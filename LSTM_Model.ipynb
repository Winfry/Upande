{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, datetime\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "df_data_5minute = pd.read_csv('AI modelling - DATA.csv')\n",
    "df_data_5minute.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "df = df_data_5minute\n",
    "close = df['close']\n",
    "df.drop(labels=['close'], axis=1, inplace=True)\n",
    "df.insert(0, 'close', close)\n",
    "\n",
    "data_train = df.iloc[:30000, :]\n",
    "data_test = df.iloc[30000:, :]\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(data_train)\n",
    "\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare LSTM input\n",
    "output_dim = 1\n",
    "batch_size = 1000\n",
    "epochs = 500\n",
    "seq_len = 5\n",
    "hidden_size = 128\n",
    "\n",
    "TIME_STEPS = 5\n",
    "INPUT_DIM = 14\n",
    "\n",
    "lstm_units = 64 \n",
    "X_train = np.array([data_train[i : i + seq_len, :] for i in range(data_train.shape[0] - seq_len)])\n",
    "y_train = np.array([data_train[i + seq_len, 0] for i in range(data_train.shape[0]- seq_len)])\n",
    "X_test = np.array([data_test[i : i + seq_len, :] for i in range(data_test.shape[0]- seq_len)])\n",
    "y_test = np.array([data_test[i + seq_len, 0] for i in range(data_test.shape[0] - seq_len)])\n",
    "maxy = y_test.max()\n",
    "miny = y_test.min()\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "inputs = Input(shape=(TIME_STEPS, INPUT_DIM))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=1, activation='relu')(inputs)  # Convolutional layer\n",
    "x = MaxPooling1D(pool_size=5)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "lstm_out = Bidirectional(LSTM(lstm_units, activation='relu'), name='bilstm')(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(lstm_out)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.save('model.h5')\n",
    "# model = load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform data to get raw values\n",
    "data_train = scaler.inverse_transform(data_train)\n",
    "data_test = scaler.inverse_transform(data_test)\n",
    "y_test = np.array([data_test[i + seq_len, 0] for i in range(data_test.shape[0] - seq_len)])\n",
    "y_train = np.array([data_train[i + seq_len, 0] for i in range(data_train.shape[0] - seq_len)])\n",
    "y_raw = np.hstack((y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Evaluation\n",
    "print('MSE Train loss:', model.evaluate(X_train, y_train, batch_size=batch_size))\n",
    "print('MSE Test loss:', model.evaluate(X_test, y_test, batch_size=batch_size))\n",
    "Rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE: ', Rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(np.arange(len(y_raw)), np.hstack((y_train, y_test)), 'b', label='Raw Data')\n",
    "plt.plot(np.arange(len(y_train), len(y_raw)), y_pred, 'r', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
